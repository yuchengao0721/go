# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}

filter { 
  grok {
    match => { "message" => "(?m)^#\s+User@Host:\s+%{USERNAME:query_user}\[[^\[\]]+\]\s+@\s+\[%{IPV4:query_ip}\]\s*Id:\s+%{BASE10NUM:id}.*#\s+Query_time:\s+%{BASE10NUM:query_time}\s+Lock_time:\s+%{BASE10NUM:lock_time}\s+Rows_sent:\s+%{BASE10NUM:rows_sent}\s+Rows_examined:\s+%{BASE10NUM:rows_examined}.*SET\s+timestamp=%{BASE10NUM:_timestamp};\s*%{GREEDYDATA:query}" 
            }
  }
  date {
    match => [ "@timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
  mutate {    
    rename => {"@timestamp" => "timestamp"}
  } 
  mutate {    
   add_field => {"log_type" => "%{[event][dataset]}" }
  } 
  #删除无用字段  
  mutate {
    remove_field => "message"    
    remove_field => "event"      
    remove_field => "tags"      
    remove_field => "service"      
    remove_field => "@version"      
    remove_field => "input" 
    remove_field => "host"
    remove_field => "ecs"
    remove_field => "agent"     
    remove_field => "log"
    remove_field => "flags"
    remove_field => "fileset"
    remove_field => "offset"
    remove_field => "file"
  } 
}

output {
  stdout {}
  http {
          http_method => "post"
          format => "json"
          url => "http://edge-alert-service:30000/log/alert"
          content_type => "application/json"
       }

}